{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4b9b0352",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T07:12:20.518400Z",
     "iopub.status.busy": "2023-08-18T07:12:20.517990Z",
     "iopub.status.idle": "2023-08-18T07:12:49.360494Z",
     "shell.execute_reply": "2023-08-18T07:12:49.359360Z"
    },
    "papermill": {
     "duration": 28.858522,
     "end_time": "2023-08-18T07:12:49.363005",
     "exception": false,
     "start_time": "2023-08-18T07:12:20.504483",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: en-core-web-sm 3.5.0\r\n",
      "Uninstalling en-core-web-sm-3.5.0:\r\n",
      "  Successfully uninstalled en-core-web-sm-3.5.0\r\n",
      "\u001b[33mWARNING: Skipping en-core-web-md as it is not installed.\u001b[0m\u001b[33m\r\n",
      "\u001b[0mFound existing installation: en-core-web-lg 3.5.0\r\n",
      "Uninstalling en-core-web-lg-3.5.0:\r\n",
      "  Successfully uninstalled en-core-web-lg-3.5.0\r\n",
      "Found existing installation: tensorflow 2.12.0\r\n",
      "Uninstalling tensorflow-2.12.0:\r\n",
      "  Successfully uninstalled tensorflow-2.12.0\r\n"
     ]
    }
   ],
   "source": [
    "!pip uninstall en-core-web-sm -y\n",
    "!pip uninstall en-core-web-md -y\n",
    "!pip uninstall en-core-web-lg -y\n",
    "!pip uninstall tensorflow -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ff4ade24",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T07:12:49.388934Z",
     "iopub.status.busy": "2023-08-18T07:12:49.388030Z",
     "iopub.status.idle": "2023-08-18T07:14:52.852043Z",
     "shell.execute_reply": "2023-08-18T07:14:52.850844Z"
    },
    "papermill": {
     "duration": 123.479302,
     "end_time": "2023-08-18T07:14:52.854654",
     "exception": false,
     "start_time": "2023-08-18T07:12:49.375352",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install --no-index --find-links /kaggle/input/data9417/ /kaggle/input/data9417/tensorflow-2.13.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n",
    "!pip install --no-index --find-links /kaggle/input/data9417/ /kaggle/input/data9417/contractions-0.1.73-py2.py3-none-any.whl\n",
    "!pip install --no-index --find-links /kaggle/input/data9417/ /kaggle/input/data9417/spacy-3.4.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n",
    "!pip install --no-index --find-links /kaggle/input/data9417/ /kaggle/input/data9417/spacy_cleaner-3.1.3-py3-none-any.whl\n",
    "\n",
    "!pip install /kaggle/input/data9417/en_core_web_sm-3.4.1-py3-none-any.whl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c61de2a5",
   "metadata": {},
   "source": [
    "### Results \n",
    "#### 0.5957 public score\n",
    "#### 0.6042 private score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43fc17f6",
   "metadata": {
    "papermill": {
     "duration": 0.017738,
     "end_time": "2023-08-18T07:14:52.889555",
     "exception": false,
     "start_time": "2023-08-18T07:14:52.871817",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Start here. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "32f2f469",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T07:14:52.924529Z",
     "iopub.status.busy": "2023-08-18T07:14:52.924203Z",
     "iopub.status.idle": "2023-08-18T07:15:03.667061Z",
     "shell.execute_reply": "2023-08-18T07:15:03.665781Z"
    },
    "papermill": {
     "duration": 10.763836,
     "end_time": "2023-08-18T07:15:03.669953",
     "exception": false,
     "start_time": "2023-08-18T07:14:52.906117",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import contractions\n",
    "import spacy\n",
    "import spacy_cleaner\n",
    "#import statsmodels.api as sm\n",
    "#import pylab as py\n",
    "from spacy_cleaner.processing import removers, replacers, mutators\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras import backend as backend\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import LSTM, Dense, Embedding, Input, dot\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5009f623",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T07:15:03.705898Z",
     "iopub.status.busy": "2023-08-18T07:15:03.705249Z",
     "iopub.status.idle": "2023-08-18T07:15:03.888197Z",
     "shell.execute_reply": "2023-08-18T07:15:03.887005Z"
    },
    "papermill": {
     "duration": 0.203261,
     "end_time": "2023-08-18T07:15:03.891133",
     "exception": false,
     "start_time": "2023-08-18T07:15:03.687872",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('/kaggle/input/feedback-prize-english-language-learning/train.csv')\n",
    "test_df = pd.read_csv('/kaggle/input/feedback-prize-english-language-learning/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a6150633",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T07:15:03.925679Z",
     "iopub.status.busy": "2023-08-18T07:15:03.925383Z",
     "iopub.status.idle": "2023-08-18T07:15:05.363837Z",
     "shell.execute_reply": "2023-08-18T07:15:05.362872Z"
    },
    "papermill": {
     "duration": 1.45842,
     "end_time": "2023-08-18T07:15:05.366458",
     "exception": false,
     "start_time": "2023-08-18T07:15:03.908038",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import random\n",
    "from albumentations.core.transforms_interface import DualTransform, BasicTransform\n",
    "from nltk import sent_tokenize\n",
    "class NLPTransform(BasicTransform):\n",
    "    \"\"\" Transform for nlp task.\"\"\"\n",
    "    LANGS = {\n",
    "        'en': 'english',\n",
    "        'it': 'italian', \n",
    "        'fr': 'french', \n",
    "        'es': 'spanish',\n",
    "        'tr': 'turkish', \n",
    "        'ru': 'russian',\n",
    "        'pt': 'portuguese'\n",
    "    }\n",
    "\n",
    "    @property\n",
    "    def targets(self):\n",
    "        return {\"data\": self.apply}\n",
    "    \n",
    "    def update_params(self, params, **kwargs):\n",
    "        if hasattr(self, \"interpolation\"):\n",
    "            params[\"interpolation\"] = self.interpolation\n",
    "        if hasattr(self, \"fill_value\"):\n",
    "            params[\"fill_value\"] = self.fill_value\n",
    "        return params\n",
    "\n",
    "    def get_sentences(self, text, lang='en'):\n",
    "        return sent_tokenize(text, self.LANGS.get(lang, 'english'))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5e7aa3c8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T07:15:05.400838Z",
     "iopub.status.busy": "2023-08-18T07:15:05.400530Z",
     "iopub.status.idle": "2023-08-18T07:15:05.406521Z",
     "shell.execute_reply": "2023-08-18T07:15:05.405505Z"
    },
    "papermill": {
     "duration": 0.025731,
     "end_time": "2023-08-18T07:15:05.408969",
     "exception": false,
     "start_time": "2023-08-18T07:15:05.383238",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#trying basic data augmentation: \n",
    "class ShuffleSentencesTransform(NLPTransform):\n",
    "    \"\"\" Do shuffle by sentence \"\"\"\n",
    "    def __init__(self, always_apply=False, p=0.5):\n",
    "        super(ShuffleSentencesTransform, self).__init__(always_apply, p)\n",
    "\n",
    "    def apply(self, data, **params):\n",
    "        text, lang = data\n",
    "        sentences = self.get_sentences(text, lang)\n",
    "        random.shuffle(sentences)\n",
    "        return ' '.join(sentences), lang\n",
    "    \n",
    "#https://www.kaggle.com/code/shonenkov/nlp-albumentations/notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "88d7972e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T07:15:05.442546Z",
     "iopub.status.busy": "2023-08-18T07:15:05.442280Z",
     "iopub.status.idle": "2023-08-18T07:15:09.128837Z",
     "shell.execute_reply": "2023-08-18T07:15:09.127452Z"
    },
    "papermill": {
     "duration": 3.706289,
     "end_time": "2023-08-18T07:15:09.131499",
     "exception": false,
     "start_time": "2023-08-18T07:15:05.425210",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_id</th>\n",
       "      <th>full_text</th>\n",
       "      <th>cohesion</th>\n",
       "      <th>syntax</th>\n",
       "      <th>vocabulary</th>\n",
       "      <th>phraseology</th>\n",
       "      <th>grammar</th>\n",
       "      <th>conventions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7817</th>\n",
       "      <td>FFD29828A873</td>\n",
       "      <td>i've been through it all and seen it all, im a...</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7818</th>\n",
       "      <td>FFD9A83B0849</td>\n",
       "      <td>Working with a group should be allowed for stu...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7819</th>\n",
       "      <td>FFDC4011AC9C</td>\n",
       "      <td>Then just die you get around the challlenge by...</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7820</th>\n",
       "      <td>FFE16D704B16</td>\n",
       "      <td>Look at Barack Obama for example, he's a black...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7821</th>\n",
       "      <td>FFED00D6E0BD</td>\n",
       "      <td>In that way they would be able to do everythin...</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           text_id                                          full_text  \\\n",
       "7817  FFD29828A873  i've been through it all and seen it all, im a...   \n",
       "7818  FFD9A83B0849  Working with a group should be allowed for stu...   \n",
       "7819  FFDC4011AC9C  Then just die you get around the challlenge by...   \n",
       "7820  FFE16D704B16  Look at Barack Obama for example, he's a black...   \n",
       "7821  FFED00D6E0BD  In that way they would be able to do everythin...   \n",
       "\n",
       "      cohesion  syntax  vocabulary  phraseology  grammar  conventions  \n",
       "7817       2.5     3.0         3.0          3.5      2.5          2.5  \n",
       "7818       4.0     4.0         4.0          4.0      3.5          3.0  \n",
       "7819       2.5     3.0         3.0          3.0      3.5          3.0  \n",
       "7820       4.0     4.5         4.5          4.0      4.5          4.5  \n",
       "7821       3.5     2.5         3.5          3.0      3.0          3.5  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transform = ShuffleSentencesTransform(p=1.0)\n",
    "transformed_list = []\n",
    "\n",
    "for iterator in train_df['full_text']:\n",
    "    text = iterator\n",
    "    lang = 'en'\n",
    "    temp_text = transform(data=(text, lang))['data'][0]\n",
    "    transformed_list.append(temp_text)\n",
    "aug_df = train_df.copy()\n",
    "aug_df['full_text'] = transformed_list\n",
    "train_df = pd.concat([train_df, aug_df], keys = 'text_id', ignore_index = True)\n",
    "train_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c9cb8717",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T07:15:09.169107Z",
     "iopub.status.busy": "2023-08-18T07:15:09.167450Z",
     "iopub.status.idle": "2023-08-18T07:15:09.175354Z",
     "shell.execute_reply": "2023-08-18T07:15:09.174525Z"
    },
    "papermill": {
     "duration": 0.028152,
     "end_time": "2023-08-18T07:15:09.177419",
     "exception": false,
     "start_time": "2023-08-18T07:15:09.149267",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = train_df.copy()\n",
    "test_feat = test_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cae986e7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T07:15:09.211431Z",
     "iopub.status.busy": "2023-08-18T07:15:09.211157Z",
     "iopub.status.idle": "2023-08-18T07:15:09.218461Z",
     "shell.execute_reply": "2023-08-18T07:15:09.217587Z"
    },
    "papermill": {
     "duration": 0.026637,
     "end_time": "2023-08-18T07:15:09.220472",
     "exception": false,
     "start_time": "2023-08-18T07:15:09.193835",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#https://www.kaggle.com/code/tangelus/english-language-learning-vectorization-lgbm\n",
    "def syllable_count(word):\n",
    "    word = word.lower()\n",
    "    count = 0\n",
    "    vowels = \"aeiouy\"\n",
    "    if word[0] in vowels:\n",
    "        count += 1\n",
    "    for index in range(1, len(word)):\n",
    "        if word[index] in vowels and word[index - 1] not in vowels:\n",
    "            count += 1\n",
    "    if word.endswith(\"e\"):\n",
    "        count -= 1\n",
    "    if count == 0:\n",
    "        count += 1\n",
    "    return count\n",
    "\n",
    "def flesch_kincaid_score(essay):\n",
    "    #206.835 - 1.015 × (total words ÷ total sentences) - 84.6 × (total syllables ÷ total words).\n",
    "    num_words = len(essay.split())\n",
    "    num_sentences = len(essay.split('.'))\n",
    "    syllables = sum([syllable_count(word) for word in essay.split()])\n",
    "    score = 206.835 - 1.015 * (num_words / num_sentences) - 84.6 * (syllables / num_words)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2e14a1d1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T07:15:09.257056Z",
     "iopub.status.busy": "2023-08-18T07:15:09.256756Z",
     "iopub.status.idle": "2023-08-18T07:15:24.351822Z",
     "shell.execute_reply": "2023-08-18T07:15:24.350559Z"
    },
    "papermill": {
     "duration": 15.117478,
     "end_time": "2023-08-18T07:15:24.354416",
     "exception": false,
     "start_time": "2023-08-18T07:15:09.236938",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# extract features from text\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "stop_words = stopwords.words('english')\n",
    "df['char_count'] = df['full_text'].apply(len)\n",
    "df['word_count'] = df['full_text'].apply(lambda x: len(x.split()))\n",
    "df['word_density'] = df['char_count'] / (df['word_count'] + 1)\n",
    "df['punctuation_count'] = df['full_text'].apply(lambda x: len(\"\".join(_ for _ in x if _ in string.punctuation))) \n",
    "df['title_word_count'] = df['full_text'].apply(lambda x: len([wrd for wrd in x.split() if wrd.istitle()]))\n",
    "df['upper_case_word_count'] = df['full_text'].apply(lambda x: len([wrd for wrd in x.split() if wrd.isupper()]))\n",
    "df['stopword_count'] = df['full_text'].apply(lambda x: len([wrd for wrd in x.split() if wrd.lower() in stop_words]))\n",
    "df['flesch_kincaid_score'] = df['full_text'].apply(lambda x: flesch_kincaid_score(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6475672f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T07:15:24.389150Z",
     "iopub.status.busy": "2023-08-18T07:15:24.388847Z",
     "iopub.status.idle": "2023-08-18T07:15:24.405444Z",
     "shell.execute_reply": "2023-08-18T07:15:24.404363Z"
    },
    "papermill": {
     "duration": 0.036305,
     "end_time": "2023-08-18T07:15:24.407637",
     "exception": false,
     "start_time": "2023-08-18T07:15:24.371332",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_id</th>\n",
       "      <th>char_count</th>\n",
       "      <th>word_count</th>\n",
       "      <th>word_density</th>\n",
       "      <th>punctuation_count</th>\n",
       "      <th>title_word_count</th>\n",
       "      <th>upper_case_word_count</th>\n",
       "      <th>stopword_count</th>\n",
       "      <th>flesch_kincaid_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0016926B079C</td>\n",
       "      <td>1387</td>\n",
       "      <td>261</td>\n",
       "      <td>5.293893</td>\n",
       "      <td>21</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>129</td>\n",
       "      <td>83.981760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0022683E9EA5</td>\n",
       "      <td>2635</td>\n",
       "      <td>533</td>\n",
       "      <td>4.934457</td>\n",
       "      <td>21</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>311</td>\n",
       "      <td>63.312381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00299B378633</td>\n",
       "      <td>1663</td>\n",
       "      <td>320</td>\n",
       "      <td>5.180685</td>\n",
       "      <td>36</td>\n",
       "      <td>27</td>\n",
       "      <td>9</td>\n",
       "      <td>177</td>\n",
       "      <td>79.293125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>003885A45F42</td>\n",
       "      <td>3973</td>\n",
       "      <td>728</td>\n",
       "      <td>5.449931</td>\n",
       "      <td>108</td>\n",
       "      <td>57</td>\n",
       "      <td>9</td>\n",
       "      <td>420</td>\n",
       "      <td>75.303750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0049B1DF5CCC</td>\n",
       "      <td>1326</td>\n",
       "      <td>234</td>\n",
       "      <td>5.642553</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>122</td>\n",
       "      <td>40.080577</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        text_id  char_count  word_count  word_density  punctuation_count  \\\n",
       "0  0016926B079C        1387         261      5.293893                 21   \n",
       "1  0022683E9EA5        2635         533      4.934457                 21   \n",
       "2  00299B378633        1663         320      5.180685                 36   \n",
       "3  003885A45F42        3973         728      5.449931                108   \n",
       "4  0049B1DF5CCC        1326         234      5.642553                  3   \n",
       "\n",
       "   title_word_count  upper_case_word_count  stopword_count  \\\n",
       "0                 3                      1             129   \n",
       "1                12                      2             311   \n",
       "2                27                      9             177   \n",
       "3                57                      9             420   \n",
       "4                 3                      0             122   \n",
       "\n",
       "   flesch_kincaid_score  \n",
       "0             83.981760  \n",
       "1             63.312381  \n",
       "2             79.293125  \n",
       "3             75.303750  \n",
       "4             40.080577  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eng_features_train = df.drop(['full_text', 'cohesion','syntax', 'vocabulary',\n",
    "       'phraseology', 'grammar', 'conventions'], axis=1)\n",
    "eng_features_train[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9e15ecce",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T07:15:24.445132Z",
     "iopub.status.busy": "2023-08-18T07:15:24.444205Z",
     "iopub.status.idle": "2023-08-18T07:15:24.466214Z",
     "shell.execute_reply": "2023-08-18T07:15:24.465380Z"
    },
    "papermill": {
     "duration": 0.042079,
     "end_time": "2023-08-18T07:15:24.468287",
     "exception": false,
     "start_time": "2023-08-18T07:15:24.426208",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_feat['char_count'] = test_feat['full_text'].apply(len)\n",
    "test_feat['word_count'] = test_feat['full_text'].apply(lambda x: len(x.split()))\n",
    "test_feat['word_density'] = test_feat['char_count'] / (test_feat['word_count'] + 1)\n",
    "test_feat['punctuation_count'] = test_feat['full_text'].apply(lambda x: len(\"\".join(_ for _ in x if _ in string.punctuation))) \n",
    "test_feat['title_word_count'] = test_feat['full_text'].apply(lambda x: len([wrd for wrd in x.split() if wrd.istitle()]))\n",
    "test_feat['upper_case_word_count'] = test_feat['full_text'].apply(lambda x: len([wrd for wrd in x.split() if wrd.isupper()]))\n",
    "test_feat['stopword_count'] = test_feat['full_text'].apply(lambda x: len([wrd for wrd in x.split() if wrd.lower() in stop_words]))\n",
    "test_feat['flesch_kincaid_score'] = test_feat['full_text'].apply(lambda x: flesch_kincaid_score(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0bdf7ad6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T07:15:24.503568Z",
     "iopub.status.busy": "2023-08-18T07:15:24.502781Z",
     "iopub.status.idle": "2023-08-18T07:15:24.515808Z",
     "shell.execute_reply": "2023-08-18T07:15:24.514823Z"
    },
    "papermill": {
     "duration": 0.033039,
     "end_time": "2023-08-18T07:15:24.518023",
     "exception": false,
     "start_time": "2023-08-18T07:15:24.484984",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_id</th>\n",
       "      <th>char_count</th>\n",
       "      <th>word_count</th>\n",
       "      <th>word_density</th>\n",
       "      <th>punctuation_count</th>\n",
       "      <th>title_word_count</th>\n",
       "      <th>upper_case_word_count</th>\n",
       "      <th>stopword_count</th>\n",
       "      <th>flesch_kincaid_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000C359D63E</td>\n",
       "      <td>4224</td>\n",
       "      <td>835</td>\n",
       "      <td>5.052632</td>\n",
       "      <td>37</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>454</td>\n",
       "      <td>67.346130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000BAD50D026</td>\n",
       "      <td>2167</td>\n",
       "      <td>386</td>\n",
       "      <td>5.599483</td>\n",
       "      <td>36</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>207</td>\n",
       "      <td>67.940871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00367BB2546B</td>\n",
       "      <td>2361</td>\n",
       "      <td>442</td>\n",
       "      <td>5.329571</td>\n",
       "      <td>33</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>244</td>\n",
       "      <td>62.349525</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        text_id  char_count  word_count  word_density  punctuation_count  \\\n",
       "0  0000C359D63E        4224         835      5.052632                 37   \n",
       "1  000BAD50D026        2167         386      5.599483                 36   \n",
       "2  00367BB2546B        2361         442      5.329571                 33   \n",
       "\n",
       "   title_word_count  upper_case_word_count  stopword_count  \\\n",
       "0                25                      1             454   \n",
       "1                11                      1             207   \n",
       "2                11                      1             244   \n",
       "\n",
       "   flesch_kincaid_score  \n",
       "0             67.346130  \n",
       "1             67.940871  \n",
       "2             62.349525  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eng_features_test = test_feat.drop(['full_text'], axis=1)\n",
    "eng_features_test[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "eb3ad868",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T07:15:24.553727Z",
     "iopub.status.busy": "2023-08-18T07:15:24.552985Z",
     "iopub.status.idle": "2023-08-18T07:20:01.570295Z",
     "shell.execute_reply": "2023-08-18T07:20:01.568695Z"
    },
    "papermill": {
     "duration": 277.038137,
     "end_time": "2023-08-18T07:20:01.573404",
     "exception": false,
     "start_time": "2023-08-18T07:15:24.535267",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cleaning Progress: 100%|██████████| 7822/7822 [04:32<00:00, 28.72it/s]\n",
      "Cleaning Progress: 100%|██████████| 3/3 [00:00<00:00,  9.29it/s]\n"
     ]
    }
   ],
   "source": [
    "proc_text = [contractions.fix(text) for text in train_df['full_text']]\n",
    "# Very fast! Measure time later\n",
    "def more_processing(text):\n",
    "    text = '<sostok> ' + text + ' <eostok>'\n",
    "    text = text.lower()\n",
    "    return text\n",
    "\n",
    "proc_text_2 = [more_processing(text) for text in proc_text]\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\", disable=['parser', 'ner'])\n",
    "#print(nlp.pipe_names)\n",
    "\n",
    "pipeline = spacy_cleaner.Pipeline(\n",
    "    nlp,\n",
    "    removers.remove_stopword_token,\n",
    "    removers.remove_punctuation_token,\n",
    "    replacers.replace_number_token,\n",
    "    mutators.mutate_lemma_token,\n",
    ")\n",
    "\n",
    "# Remember to switch n_process to 4 when running on Kaggle.\n",
    "\n",
    "proc_text_3 = pipeline.clean(proc_text_2, n_process = 4, batch_size = 12)\n",
    "\n",
    "#proc_text_3 = pd.read_pickle(\"/kaggle/input/data9417/proc_text_3.pkl\")\n",
    "\n",
    "# Also added start of seq and end of seq, lowercase\n",
    "train_df['cleaned_text'] = proc_text_3\n",
    "\n",
    "train_df.head()\n",
    "\n",
    "proc_test = [contractions.fix(text) for text in test_df['full_text']]\n",
    "# Very fast! Measure time later\n",
    "def more_processing(text):\n",
    "    text = '<sostok> ' + text + ' <eostok>'\n",
    "    text = text.lower()\n",
    "    return text\n",
    "\n",
    "proc_test_2 = [more_processing(text) for text in proc_test]\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\", disable=['parser', 'ner'])\n",
    "#print(nlp.pipe_names)\n",
    "\n",
    "pipeline = spacy_cleaner.Pipeline(\n",
    "    nlp,\n",
    "    removers.remove_stopword_token,\n",
    "    removers.remove_punctuation_token,\n",
    "    replacers.replace_number_token,\n",
    "    mutators.mutate_lemma_token,\n",
    ")\n",
    "\n",
    "# Remember to switch n_process to 4 when running on Kaggle.\n",
    "\n",
    "proc_test_3 = pipeline.clean(proc_test_2, n_process = 4, batch_size = 12)\n",
    "\n",
    "test_df['cleaned_text'] = proc_test_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a4254274",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T07:20:01.892651Z",
     "iopub.status.busy": "2023-08-18T07:20:01.892264Z",
     "iopub.status.idle": "2023-08-18T07:20:01.914833Z",
     "shell.execute_reply": "2023-08-18T07:20:01.913923Z"
    },
    "papermill": {
     "duration": 0.174019,
     "end_time": "2023-08-18T07:20:01.916984",
     "exception": false,
     "start_time": "2023-08-18T07:20:01.742965",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_df = pd.concat([train_df, eng_features_train], keys = 'text_id', axis = 1)\n",
    "test_df = pd.concat([test_df, eng_features_test], keys = 'text_id', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2568e8ce",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T07:20:02.214367Z",
     "iopub.status.busy": "2023-08-18T07:20:02.214009Z",
     "iopub.status.idle": "2023-08-18T07:20:02.229865Z",
     "shell.execute_reply": "2023-08-18T07:20:02.228842Z"
    },
    "papermill": {
     "duration": 0.167455,
     "end_time": "2023-08-18T07:20:02.232152",
     "exception": false,
     "start_time": "2023-08-18T07:20:02.064697",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Just fixing the column name problem.\n",
    "df_1_cols = train_df['t'].columns.to_numpy()\n",
    "df_2_cols = train_df['e'].columns.to_numpy()\n",
    "#columns_1.extend(columns_2)\n",
    "columns_1 = [x for x in df_1_cols]\n",
    "columns_2 = [x for x in df_2_cols]\n",
    "columns_total = columns_1 + columns_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7f55ff84",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T07:20:02.535290Z",
     "iopub.status.busy": "2023-08-18T07:20:02.534923Z",
     "iopub.status.idle": "2023-08-18T07:20:02.539577Z",
     "shell.execute_reply": "2023-08-18T07:20:02.538678Z"
    },
    "papermill": {
     "duration": 0.156398,
     "end_time": "2023-08-18T07:20:02.541647",
     "exception": false,
     "start_time": "2023-08-18T07:20:02.385249",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_df.columns = columns_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fdb3c831",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T07:20:02.883525Z",
     "iopub.status.busy": "2023-08-18T07:20:02.883177Z",
     "iopub.status.idle": "2023-08-18T07:20:02.893888Z",
     "shell.execute_reply": "2023-08-18T07:20:02.892865Z"
    },
    "papermill": {
     "duration": 0.161257,
     "end_time": "2023-08-18T07:20:02.896125",
     "exception": false,
     "start_time": "2023-08-18T07:20:02.734868",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Just fixing the column name problem.\n",
    "df_1_cols = test_df['t'].columns.to_numpy()\n",
    "df_2_cols = test_df['e'].columns.to_numpy()\n",
    "#columns_1.extend(columns_2)\n",
    "columns_1 = [x for x in df_1_cols]\n",
    "columns_2 = [x for x in df_2_cols]\n",
    "columns_total = columns_1 + columns_2\n",
    "test_df.columns = columns_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8edb30d9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T07:20:03.193716Z",
     "iopub.status.busy": "2023-08-18T07:20:03.193368Z",
     "iopub.status.idle": "2023-08-18T07:20:03.211715Z",
     "shell.execute_reply": "2023-08-18T07:20:03.210848Z"
    },
    "papermill": {
     "duration": 0.168956,
     "end_time": "2023-08-18T07:20:03.213855",
     "exception": false,
     "start_time": "2023-08-18T07:20:03.044899",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_id</th>\n",
       "      <th>full_text</th>\n",
       "      <th>cleaned_text</th>\n",
       "      <th>text_id</th>\n",
       "      <th>char_count</th>\n",
       "      <th>word_count</th>\n",
       "      <th>word_density</th>\n",
       "      <th>punctuation_count</th>\n",
       "      <th>title_word_count</th>\n",
       "      <th>upper_case_word_count</th>\n",
       "      <th>stopword_count</th>\n",
       "      <th>flesch_kincaid_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000C359D63E</td>\n",
       "      <td>when a person has no experience on a job their...</td>\n",
       "      <td>&lt; sostok &gt; person experience job go good peopl...</td>\n",
       "      <td>0000C359D63E</td>\n",
       "      <td>4224</td>\n",
       "      <td>835</td>\n",
       "      <td>5.052632</td>\n",
       "      <td>37</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>454</td>\n",
       "      <td>67.346130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000BAD50D026</td>\n",
       "      <td>Do you think students would benefit from being...</td>\n",
       "      <td>&lt; sostok &gt; think student benefit able attend c...</td>\n",
       "      <td>000BAD50D026</td>\n",
       "      <td>2167</td>\n",
       "      <td>386</td>\n",
       "      <td>5.599483</td>\n",
       "      <td>36</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>207</td>\n",
       "      <td>67.940871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00367BB2546B</td>\n",
       "      <td>Thomas Jefferson once states that \"it is wonde...</td>\n",
       "      <td>&lt; sostok &gt; thomas jefferson state wonderful ag...</td>\n",
       "      <td>00367BB2546B</td>\n",
       "      <td>2361</td>\n",
       "      <td>442</td>\n",
       "      <td>5.329571</td>\n",
       "      <td>33</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>244</td>\n",
       "      <td>62.349525</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        text_id                                          full_text  \\\n",
       "0  0000C359D63E  when a person has no experience on a job their...   \n",
       "1  000BAD50D026  Do you think students would benefit from being...   \n",
       "2  00367BB2546B  Thomas Jefferson once states that \"it is wonde...   \n",
       "\n",
       "                                        cleaned_text       text_id  \\\n",
       "0  < sostok > person experience job go good peopl...  0000C359D63E   \n",
       "1  < sostok > think student benefit able attend c...  000BAD50D026   \n",
       "2  < sostok > thomas jefferson state wonderful ag...  00367BB2546B   \n",
       "\n",
       "   char_count  word_count  word_density  punctuation_count  title_word_count  \\\n",
       "0        4224         835      5.052632                 37                25   \n",
       "1        2167         386      5.599483                 36                11   \n",
       "2        2361         442      5.329571                 33                11   \n",
       "\n",
       "   upper_case_word_count  stopword_count  flesch_kincaid_score  \n",
       "0                      1             454             67.346130  \n",
       "1                      1             207             67.940871  \n",
       "2                      1             244             62.349525  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "76acb265",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T07:20:03.515287Z",
     "iopub.status.busy": "2023-08-18T07:20:03.514937Z",
     "iopub.status.idle": "2023-08-18T07:20:07.073545Z",
     "shell.execute_reply": "2023-08-18T07:20:07.072594Z"
    },
    "papermill": {
     "duration": 3.711715,
     "end_time": "2023-08-18T07:20:07.076166",
     "exception": false,
     "start_time": "2023-08-18T07:20:03.364451",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'percent': 52.24, 'total_coverage': 1.4, 'count': 9088, 'total_count': 17397}\n",
      "{'percent': 49.91, 'total_coverage': 0.66, 'count': 11065, 'total_count': 22169}\n",
      "[{2, 'showers'}, {2, 'mos'}, {2, 'homeles'}, {2, 'wount'}, {2, 'trowing'}, {2, 'estudnets'}, {'arctecture', 2}, {'estared', 2}, {'potition', 2}, {2, 'arquicteture'}, {2, 'thirt'}, {\"cann't\", 2}, {'beatifull', 2}, {2, 'selfcondifence'}, {'impotently', 2}, {2, 'selfcondience'}, {'battlefield', 2}, {2, 'selfcondicence'}, {2, 'selfcondidence'}, {'incuage', 2}, {2, 'circulating'}, {'corovirus', 2}, {'highschol', 2}, {2, 'grocerys'}, {2, 'thenthey'}, {2, 'aruge'}, {'techbology', 2}, {2, 'surgical'}, {2, \"expensive's\"}, {2, \"sticker's\"}, {'terror', 2}, {'tees', 2}, {'20019', 2}, {2, 'pedophiles'}, {2, 'nutrients'}, {2, 'interducaions'}, {2, 'warmest'}, {2, 'enjoble'}, {2, 'consecrate'}, {'paragargh', 2}, {2, 'bey'}, {2, 'wannna'}, {'remebers', 2}, {2, 'balmy'}, {2, 'reaserch'}, {2, \"classmates'\"}, {\"class'\", 2}, {'aggravated', 2}, {'captures', 2}, {2, 'carelessly'}, {'hypothesize', 2}, {2, 'availadle'}, {'behefit', 2}, {2, 'deing'}, {'serios', 2}, {2, 'homewark'}, {'houes', 2}, {2, 'restaurent'}, {'differenly', 2}, {2, 'disavanges'}, {'prechers', 2}, {'prepere', 2}, {2, 'whow'}, {2, 'bitween'}, {2, 'fourty'}, {2, \"employees'\"}, {'recures', 2}, {'respectfuly', 2}, {'sothing', 2}, {'someelse', 2}, {2, 'exito'}, {'pertmit', 2}, {2, 'bult'}, {2, 'misteke'}, {2, 'exating'}, {'impediments', 2}, {2, \"enthusiasms''\"}, {\"failure''\", 2}, {2, \"''somebody''\"}, {2, 'degeneres'}, {\"'''enthusiasms''\", 2}, {\"''failures''\", 2}, {2, \"''fake\"}, {2, \"honesty's\"}, {2, 'guessed'}, {'reteach', 2}, {'revolution', 2}, {2, '2pm'}, {\"''family\", 2}, {\"student''\", 2}, {2, \"''a\"}, {2, \"monkey''\"}, {'holland', 2}, {2, 'ireland'}, {\"''life\", 2}, {2, \"harder''\"}, {2, 'cuss'}, {2, 'busting'}, {'butts', 2}, {2, 'opions'}]\n"
     ]
    }
   ],
   "source": [
    "# rare word analysis\n",
    "def get_rare_word_percent(tokenizer, threshold):\n",
    "    # threshold: if the word's occurrence is less than this then it's rare word\n",
    "\n",
    "    count = 0\n",
    "    total_count = 0\n",
    "    frequency = 0\n",
    "    total_frequency = 0\n",
    "    rare_words = []\n",
    "\n",
    "    for key, value in tokenizer.word_counts.items():\n",
    "        total_count += 1\n",
    "        total_frequency += value\n",
    "        if value < threshold:\n",
    "            rare_words.append({key, value})\n",
    "            count += 1\n",
    "            frequency += value\n",
    "    print({\n",
    "        'percent': round((count / total_count) * 100, 2),\n",
    "        'total_coverage': round(frequency / total_frequency * 100, 2),\n",
    "        'count': count,\n",
    "        'total_count': total_count\n",
    "        })\n",
    "\n",
    "    return rare_words\n",
    "\n",
    "# This is a different tokenizer to the one built into SpaCy\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "x_tokenizer = Tokenizer()\n",
    "x_tokenizer.fit_on_texts(train_df['cleaned_text'])\n",
    "\n",
    "rare_words = get_rare_word_percent(x_tokenizer, 4)\n",
    "#print(rare_words)\n",
    "\n",
    "#rare_words[:100]\n",
    "#mostly typos in otherwise normal\n",
    "\n",
    "org_tokenizer = Tokenizer()\n",
    "org_tokenizer.fit_on_texts(train_df['full_text'])\n",
    "\n",
    "rare_words_2 = get_rare_word_percent(org_tokenizer, 4)\n",
    "#print(rare_words)\n",
    "\n",
    "print(rare_words_2[:100])\n",
    "#typos exist in original sentences too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fe819b87",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T07:20:07.374014Z",
     "iopub.status.busy": "2023-08-18T07:20:07.373075Z",
     "iopub.status.idle": "2023-08-18T07:20:07.397894Z",
     "shell.execute_reply": "2023-08-18T07:20:07.396500Z"
    },
    "papermill": {
     "duration": 0.176757,
     "end_time": "2023-08-18T07:20:07.400671",
     "exception": false,
     "start_time": "2023-08-18T07:20:07.223914",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train_full, x_val_full, y_train, y_val = train_test_split(np.array(train_df[['cleaned_text', 'char_count', 'word_count', 'word_density',\n",
    "                                                                     'punctuation_count', 'title_word_count', 'upper_case_word_count',\n",
    "                                                                   'stopword_count', 'flesch_kincaid_score']]), np.array(train_df[['cohesion', 'syntax', 'vocabulary',\n",
    "                                                                                  'phraseology', 'grammar', 'conventions']]), test_size = 0.05, random_state = 0, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d85ec701",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T07:20:07.767211Z",
     "iopub.status.busy": "2023-08-18T07:20:07.766842Z",
     "iopub.status.idle": "2023-08-18T07:20:07.771642Z",
     "shell.execute_reply": "2023-08-18T07:20:07.770738Z"
    },
    "papermill": {
     "duration": 0.169535,
     "end_time": "2023-08-18T07:20:07.773574",
     "exception": false,
     "start_time": "2023-08-18T07:20:07.604039",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "x_train = x_train_full[:, 0]\n",
    "x_train_feats = x_train_full[:, 1:]\n",
    "x_val = x_val_full[:, 0]\n",
    "x_val_feats = x_val_full[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b6373c44",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T07:20:08.072549Z",
     "iopub.status.busy": "2023-08-18T07:20:08.072208Z",
     "iopub.status.idle": "2023-08-18T07:20:08.078671Z",
     "shell.execute_reply": "2023-08-18T07:20:08.077760Z"
    },
    "papermill": {
     "duration": 0.157995,
     "end_time": "2023-08-18T07:20:08.081096",
     "exception": false,
     "start_time": "2023-08-18T07:20:07.923101",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2326, 401, 5.786069651741293, 44, 23, 1, 208, 67.55522513161543],\n",
       "       [4208, 746, 5.633199464524766, 86, 57, 12, 385, 65.17338914890718],\n",
       "       [998, 189, 5.252631578947368, 16, 10, 2, 91, 72.00142857142859],\n",
       "       [1148, 232, 4.927038626609442, 18, 11, 3, 143, 84.01425287356324],\n",
       "       [3484, 626, 5.556618819776714, 66, 56, 9, 340, 70.51915257539159]],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_feats[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "13fe997a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T07:20:08.378364Z",
     "iopub.status.busy": "2023-08-18T07:20:08.377463Z",
     "iopub.status.idle": "2023-08-18T07:20:08.467840Z",
     "shell.execute_reply": "2023-08-18T07:20:08.466497Z"
    },
    "papermill": {
     "duration": 0.241982,
     "end_time": "2023-08-18T07:20:08.470045",
     "exception": false,
     "start_time": "2023-08-18T07:20:08.228063",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "# To check how many rows in a column has length (of the text) <= limit\n",
    "def get_word_percent(column, limit):\n",
    "    count = 0\n",
    "    for sentence in column:\n",
    "        if len(sentence.split()) <= limit:\n",
    "            count += 1\n",
    "\n",
    "    return round(count / len(column), 2)\n",
    "\n",
    "\n",
    "# Check how many % of headlines have 0-430 words\n",
    "print(get_word_percent(train_df.cleaned_text, 430))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "de9e1d4f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T07:20:08.772826Z",
     "iopub.status.busy": "2023-08-18T07:20:08.772437Z",
     "iopub.status.idle": "2023-08-18T07:20:09.616194Z",
     "shell.execute_reply": "2023-08-18T07:20:09.614817Z"
    },
    "papermill": {
     "duration": 0.998242,
     "end_time": "2023-08-18T07:20:09.618503",
     "exception": false,
     "start_time": "2023-08-18T07:20:08.620261",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17398\n",
      "(7430, 450)\n",
      "(7430, 6)\n",
      "(392, 450)\n",
      "(392, 6)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "max_text_len = 450\n",
    "x_train_sequence = x_tokenizer.texts_to_sequences(x_train)\n",
    "x_val_sequence = x_tokenizer.texts_to_sequences(x_val)\n",
    "\n",
    "# padding upto max_text_len\n",
    "x_train_padded = pad_sequences(x_train_sequence, maxlen=max_text_len, padding='pre')\n",
    "x_val_padded = pad_sequences(x_val_sequence, maxlen=max_text_len, padding='pre')\n",
    "\n",
    "x_vocab_size = len(x_tokenizer.word_index) + 1\n",
    "\n",
    "print(x_vocab_size)\n",
    "\n",
    "print(x_train_padded.shape)\n",
    "print(y_train.shape)\n",
    "print(x_val_padded.shape)\n",
    "print(y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b5676677",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T07:20:09.920988Z",
     "iopub.status.busy": "2023-08-18T07:20:09.920010Z",
     "iopub.status.idle": "2023-08-18T07:20:17.215329Z",
     "shell.execute_reply": "2023-08-18T07:20:17.214035Z"
    },
    "papermill": {
     "duration": 7.448081,
     "end_time": "2023-08-18T07:20:17.217642",
     "exception": false,
     "start_time": "2023-08-18T07:20:09.769561",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 400000 word vectors.\n",
      "Converted 10101 words (7296 misses)\n"
     ]
    }
   ],
   "source": [
    "def get_embedding_matrix(tokenizer, embedding_dim, vocab_size=None):\n",
    "    word_index = tokenizer.word_index\n",
    "    voc = list(word_index.keys())\n",
    "\n",
    "    path_to_glove_file = '/kaggle/input/glove50/glove.6B.50d.txt'\n",
    "\n",
    "    embeddings_index = {}\n",
    "    with open(path_to_glove_file) as f:\n",
    "        for line in f:\n",
    "            word, coefs = line.split(maxsplit=1)\n",
    "            coefs = np.fromstring(coefs, \"f\", sep=\" \")\n",
    "            embeddings_index[word] = coefs\n",
    "\n",
    "    print(\"Found %s word vectors.\" % len(embeddings_index))\n",
    "\n",
    "    num_tokens = len(voc) + 2 if not vocab_size else vocab_size\n",
    "    hits = 0\n",
    "    misses = 0\n",
    "\n",
    "    # Prepare embedding matrix\n",
    "    embedding_matrix = np.zeros((num_tokens, embedding_dim))\n",
    "    for word, i in word_index.items():\n",
    "        embedding_vector = embeddings_index.get(word)\n",
    "        if embedding_vector is not None:\n",
    "            # Words not found in embedding index will be all-zeros.\n",
    "            # This includes the representation for \"padding\" and \"OOV\"\n",
    "            embedding_matrix[i] = embedding_vector\n",
    "            #print(\"Word, i : \", word, i)\n",
    "            hits += 1\n",
    "        else:\n",
    "            misses += 1\n",
    "    print(\"Converted %d words (%d misses)\" % (hits, misses))\n",
    "\n",
    "    return embedding_matrix\n",
    "\n",
    "embedding_dim = 50\n",
    "x_embedding_matrix = get_embedding_matrix(x_tokenizer, embedding_dim, x_vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4f61d387",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T07:20:17.526557Z",
     "iopub.status.busy": "2023-08-18T07:20:17.525749Z",
     "iopub.status.idle": "2023-08-18T07:20:17.538122Z",
     "shell.execute_reply": "2023-08-18T07:20:17.537067Z"
    },
    "papermill": {
     "duration": 0.173655,
     "end_time": "2023-08-18T07:20:17.541146",
     "exception": false,
     "start_time": "2023-08-18T07:20:17.367491",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#root mean squared error\n",
    "from keras import backend as K \n",
    "def root_mean_squared_error(y):\n",
    "    y_true = y[0]\n",
    "    y_pred = y[1]\n",
    "    return K.sqrt(K.mean(K.square(y_pred - y_true))) \n",
    "\n",
    "#tensor containing the RMSE for each column.\n",
    "def mean_columnwise_root_mean_squared_error(y_true, y_pred):\n",
    "    all_rmse = tf.map_fn(root_mean_squared_error, (y_true, y_pred), dtype=tf.float32)\n",
    "    return K.mean(all_rmse)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8d6d85ee",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T07:20:17.877208Z",
     "iopub.status.busy": "2023-08-18T07:20:17.876847Z",
     "iopub.status.idle": "2023-08-18T07:20:22.192738Z",
     "shell.execute_reply": "2023-08-18T07:20:22.191862Z"
    },
    "papermill": {
     "duration": 4.491598,
     "end_time": "2023-08-18T07:20:22.215563",
     "exception": false,
     "start_time": "2023-08-18T07:20:17.723965",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)        [(None, 450)]                0         []                            \n",
      "                                                                                                  \n",
      " embedding (Embedding)       (None, 450, 50)              869900    ['input_1[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d (Conv1D)             (None, 449, 128)             12928     ['embedding[0][0]']           \n",
      "                                                                                                  \n",
      " input_2 (InputLayer)        [(None, 8)]                  0         []                            \n",
      "                                                                                                  \n",
      " conv1d_1 (Conv1D)           (None, 448, 128)             32896     ['conv1d[0][0]']              \n",
      "                                                                                                  \n",
      " dense (Dense)               (None, 32)                   288       ['input_2[0][0]']             \n",
      "                                                                                                  \n",
      " dropout (Dropout)           (None, 448, 128)             0         ['conv1d_1[0][0]']            \n",
      "                                                                                                  \n",
      " dense_1 (Dense)             (None, 32)                   1056      ['dense[0][0]']               \n",
      "                                                                                                  \n",
      " global_average_pooling1d (  (None, 128)                  0         ['dropout[0][0]']             \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " batch_normalization (Batch  (None, 32)                   128       ['dense_1[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_1 (Bat  (None, 128)                  512       ['global_average_pooling1d[0][\n",
      " chNormalization)                                                   0]']                          \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)   (None, 160)                  0         ['batch_normalization[0][0]', \n",
      "                                                                     'batch_normalization_1[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " dense_2 (Dense)             (None, 64)                   10304     ['concatenate[0][0]']         \n",
      "                                                                                                  \n",
      " dense_3 (Dense)             (None, 6)                    390       ['dense_2[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 928402 (3.54 MB)\n",
      "Trainable params: 58182 (227.27 KB)\n",
      "Non-trainable params: 870220 (3.32 MB)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import backend as backend\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import MaxPooling1D, GlobalAveragePooling1D, Conv1D\n",
    "from tensorflow.keras.layers import BatchNormalization, Concatenate, LSTM, Dense, Embedding, Input, dot, Dropout\n",
    "import tensorflow as tf\n",
    "backend.clear_session()\n",
    "input_dim = len(x_train_padded[0])\n",
    "essay_input= Input(shape = (input_dim, ))\n",
    "features_input = Input(shape = (8,))\n",
    "embedding_layer = Embedding(input_dim = x_vocab_size, \n",
    "                    output_dim = embedding_dim, \n",
    "                    embeddings_initializer = tf.keras.initializers.Constant(x_embedding_matrix),\n",
    "                    input_length=max_text_len, trainable = False, mask_zero = True)(essay_input)\n",
    "\n",
    "# Convolutional layers for the essays input\n",
    "conv_1 = Conv1D(128, 2, activation = 'relu')(embedding_layer)\n",
    "conv_2 = Conv1D(128, 2, activation = 'relu')(conv_1)\n",
    "\n",
    "# Dense layers for the other features\n",
    "dense_1 = Dense(32, activation = 'relu')(features_input)\n",
    "# Softmax outputs probabilities of each of the 8 features falling into 4 different classes. \n",
    "dense_2 = Dense(32, activation = 'softmax')(dense_1)\n",
    "normalization_1 = BatchNormalization()(dense_2)\n",
    "\n",
    "# Dropout\n",
    "dropout_1 = Dropout(0.2)(conv_2)\n",
    "\n",
    "#conv_3 = Conv1D(128, 2, activation = 'relu')(dropout_1)\n",
    "#conv_4 = Conv1D(128, 2, activation = 'relu')(conv_3)\n",
    "\n",
    "# Dropout\n",
    "#dropout_2 = Dropout(0.2)(conv_4)\n",
    "\n",
    "# Pooling\n",
    "pooling_layer = GlobalAveragePooling1D()(dropout_1)\n",
    "normalization_2 = BatchNormalization()(pooling_layer)\n",
    "\n",
    "# Concatenate\n",
    "concat_layer = Concatenate()([normalization_1, normalization_2])\n",
    "\n",
    "# Dense layer\n",
    "dense_3 = Dense(64, activation = 'relu')(concat_layer)\n",
    "\n",
    "# Output\n",
    "output_layer = Dense(6)(dense_3)\n",
    "\n",
    "model = Model(inputs=[essay_input, features_input], outputs=output_layer)\n",
    "optimizer_obj = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "model.compile(optimizer=optimizer_obj, loss=mean_columnwise_root_mean_squared_error)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4f3a753b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T07:20:22.525592Z",
     "iopub.status.busy": "2023-08-18T07:20:22.525239Z",
     "iopub.status.idle": "2023-08-18T07:20:22.538492Z",
     "shell.execute_reply": "2023-08-18T07:20:22.537575Z"
    },
    "papermill": {
     "duration": 0.170656,
     "end_time": "2023-08-18T07:20:22.540494",
     "exception": false,
     "start_time": "2023-08-18T07:20:22.369838",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.3260000e+03, 4.0100000e+02, 5.7860699e+00, 4.4000000e+01,\n",
       "        2.3000000e+01, 1.0000000e+00, 2.0800000e+02, 6.7555222e+01],\n",
       "       [4.2080000e+03, 7.4600000e+02, 5.6331997e+00, 8.6000000e+01,\n",
       "        5.7000000e+01, 1.2000000e+01, 3.8500000e+02, 6.5173386e+01],\n",
       "       [9.9800000e+02, 1.8900000e+02, 5.2526317e+00, 1.6000000e+01,\n",
       "        1.0000000e+01, 2.0000000e+00, 9.1000000e+01, 7.2001427e+01],\n",
       "       [1.1480000e+03, 2.3200000e+02, 4.9270387e+00, 1.8000000e+01,\n",
       "        1.1000000e+01, 3.0000000e+00, 1.4300000e+02, 8.4014252e+01],\n",
       "       [3.4840000e+03, 6.2600000e+02, 5.5566187e+00, 6.6000000e+01,\n",
       "        5.6000000e+01, 9.0000000e+00, 3.4000000e+02, 7.0519150e+01]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_feats = np.asarray(x_train_feats).astype('float32')\n",
    "x_val_feats = np.asarray(x_val_feats).astype('float32')\n",
    "x_train_feats[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c2af46d6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T07:20:22.895771Z",
     "iopub.status.busy": "2023-08-18T07:20:22.895410Z",
     "iopub.status.idle": "2023-08-18T07:20:22.906294Z",
     "shell.execute_reply": "2023-08-18T07:20:22.905268Z"
    },
    "papermill": {
     "duration": 0.170885,
     "end_time": "2023-08-18T07:20:22.908496",
     "exception": false,
     "start_time": "2023-08-18T07:20:22.737611",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.37638378, 0.3105939 , 0.044139  , 0.21568628, 0.11386138,\n",
       "        0.00271003, 0.2689747 , 0.921026  ],\n",
       "       [0.6920497 , 0.58747995, 0.03955369, 0.42156863, 0.28217822,\n",
       "        0.03252032, 0.5046604 , 0.91484606],\n",
       "       [0.15363972, 0.14044943, 0.02813861, 0.07843138, 0.04950495,\n",
       "        0.00542005, 0.11318242, 0.9325621 ],\n",
       "       [0.17879906, 0.17495987, 0.01837251, 0.0882353 , 0.05445544,\n",
       "        0.00813008, 0.18242343, 0.9637305 ],\n",
       "       [0.5706139 , 0.49117178, 0.03725666, 0.32352942, 0.27722773,\n",
       "        0.02439024, 0.44474033, 0.9287162 ]], dtype=float32)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(x_train_feats)\n",
    "x_train_feats_scaled = scaler.transform(x_train_feats)\n",
    "x_val_feats_scaled = scaler.transform(x_val_feats)\n",
    "x_train_feats_scaled[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bdc684b9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T07:20:23.215481Z",
     "iopub.status.busy": "2023-08-18T07:20:23.215153Z",
     "iopub.status.idle": "2023-08-18T07:20:23.221512Z",
     "shell.execute_reply": "2023-08-18T07:20:23.220587Z"
    },
    "papermill": {
     "duration": 0.159836,
     "end_time": "2023-08-18T07:20:23.223536",
     "exception": false,
     "start_time": "2023-08-18T07:20:23.063700",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "callbacks = [\n",
    "    EarlyStopping(monitor='val_loss',\n",
    "                  mode='min', verbose=1, patience=3, min_delta = 0.002),\n",
    "    ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=1, min_lr=0.000001, verbose=1),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "dfaec1b3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T07:20:23.528066Z",
     "iopub.status.busy": "2023-08-18T07:20:23.527171Z",
     "iopub.status.idle": "2023-08-18T07:22:11.521174Z",
     "shell.execute_reply": "2023-08-18T07:22:11.520354Z"
    },
    "papermill": {
     "duration": 108.147364,
     "end_time": "2023-08-18T07:22:11.523238",
     "exception": false,
     "start_time": "2023-08-18T07:20:23.375874",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "117/117 [==============================] - 17s 61ms/step - loss: 1.2624 - val_loss: 0.6436 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "117/117 [==============================] - 7s 58ms/step - loss: 0.5603 - val_loss: 0.5915 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "117/117 [==============================] - 7s 59ms/step - loss: 0.5247 - val_loss: 0.5852 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "117/117 [==============================] - 8s 65ms/step - loss: 0.5063 - val_loss: 0.5429 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "117/117 [==============================] - 7s 58ms/step - loss: 0.4941 - val_loss: 0.5354 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "116/117 [============================>.] - ETA: 0s - loss: 0.4885\n",
      "Epoch 6: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "117/117 [==============================] - 7s 57ms/step - loss: 0.4886 - val_loss: 0.5656 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "117/117 [==============================] - 7s 58ms/step - loss: 0.4611 - val_loss: 0.4860 - lr: 1.0000e-04\n",
      "Epoch 8/20\n",
      "117/117 [==============================] - 7s 60ms/step - loss: 0.4531 - val_loss: 0.4835 - lr: 1.0000e-04\n",
      "Epoch 9/20\n",
      "117/117 [==============================] - 7s 62ms/step - loss: 0.4490 - val_loss: 0.4795 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "117/117 [==============================] - 7s 59ms/step - loss: 0.4469 - val_loss: 0.4789 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "117/117 [==============================] - 7s 57ms/step - loss: 0.4423 - val_loss: 0.4750 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "116/117 [============================>.] - ETA: 0s - loss: 0.4405\n",
      "Epoch 12: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "117/117 [==============================] - 7s 58ms/step - loss: 0.4405 - val_loss: 0.4761 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "117/117 [==============================] - 7s 62ms/step - loss: 0.4376 - val_loss: 0.4738 - lr: 1.0000e-05\n",
      "Epoch 14/20\n",
      "116/117 [============================>.] - ETA: 0s - loss: 0.4368\n",
      "Epoch 14: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "117/117 [==============================] - 7s 59ms/step - loss: 0.4368 - val_loss: 0.4739 - lr: 1.0000e-05\n",
      "Epoch 14: early stopping\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x = [x_train_padded, x_train_feats_scaled], y = y_train, epochs=20, validation_data=([x_val_padded, x_val_feats_scaled], y_val), batch_size = 64, callbacks = callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a60df9b4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T07:22:12.077940Z",
     "iopub.status.busy": "2023-08-18T07:22:12.076905Z",
     "iopub.status.idle": "2023-08-18T07:22:12.084782Z",
     "shell.execute_reply": "2023-08-18T07:22:12.083871Z"
    },
    "papermill": {
     "duration": 0.285967,
     "end_time": "2023-08-18T07:22:12.086954",
     "exception": false,
     "start_time": "2023-08-18T07:22:11.800987",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def clean_input(df):\n",
    "    proc_text = [contractions.fix(text) for text in df['full_text']]\n",
    "    # Very fast! Measure time later\n",
    "    def more_processing(text):\n",
    "        text = '<sostok> ' + text + ' <eostok>'\n",
    "        text = text.lower()\n",
    "        return text\n",
    "\n",
    "    proc_text_2 = [more_processing(text) for text in proc_text]\n",
    "    nlp = spacy.load(\"en_core_web_sm\", disable=['senter', 'parser', 'ner'])\n",
    "    print(nlp.pipe_names)\n",
    "\n",
    "    pipeline = spacy_cleaner.Pipeline(\n",
    "      nlp,\n",
    "      removers.remove_stopword_token,\n",
    "      removers.remove_punctuation_token,\n",
    "      replacers.replace_number_token,\n",
    "      mutators.mutate_lemma_token,\n",
    "    )\n",
    "    cleaned_text = pipeline.clean(proc_text_2, n_process = 8, batch_size = 12)\n",
    "    return cleaned_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6ab0774f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T07:22:12.690838Z",
     "iopub.status.busy": "2023-08-18T07:22:12.689854Z",
     "iopub.status.idle": "2023-08-18T07:22:12.697493Z",
     "shell.execute_reply": "2023-08-18T07:22:12.696413Z"
    },
    "papermill": {
     "duration": 0.33198,
     "end_time": "2023-08-18T07:22:12.699583",
     "exception": false,
     "start_time": "2023-08-18T07:22:12.367603",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_training_data(df, x_tokenizer, mode='fit'):\n",
    "    X = []\n",
    "    y = []\n",
    "\n",
    "    x_sequence = x_tokenizer.texts_to_sequences(df['cleaned_text'])\n",
    "    X = pad_sequences(x_sequence, maxlen=max_text_len, padding='pre')\n",
    "\n",
    "    if mode == 'fit':\n",
    "        for index, row in df.iterrows():\n",
    "            labels = [row['cohesion'], row['syntax'], row['vocabulary'], row['phraseology'], row['grammar'], row['conventions']]\n",
    "            y.append(labels)\n",
    "\n",
    "    if mode == 'fit':\n",
    "        return np.array(X), np.array(y)\n",
    "    else:\n",
    "        return np.array(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fff57ea7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T07:22:13.248400Z",
     "iopub.status.busy": "2023-08-18T07:22:13.248045Z",
     "iopub.status.idle": "2023-08-18T07:22:13.262251Z",
     "shell.execute_reply": "2023-08-18T07:22:13.261277Z"
    },
    "papermill": {
     "duration": 0.290195,
     "end_time": "2023-08-18T07:22:13.264193",
     "exception": false,
     "start_time": "2023-08-18T07:22:12.973998",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_id</th>\n",
       "      <th>full_text</th>\n",
       "      <th>char_count</th>\n",
       "      <th>word_count</th>\n",
       "      <th>word_density</th>\n",
       "      <th>punctuation_count</th>\n",
       "      <th>title_word_count</th>\n",
       "      <th>upper_case_word_count</th>\n",
       "      <th>stopword_count</th>\n",
       "      <th>flesch_kincaid_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000C359D63E</td>\n",
       "      <td>when a person has no experience on a job their...</td>\n",
       "      <td>4224</td>\n",
       "      <td>835</td>\n",
       "      <td>5.052632</td>\n",
       "      <td>37</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>454</td>\n",
       "      <td>67.346130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000BAD50D026</td>\n",
       "      <td>Do you think students would benefit from being...</td>\n",
       "      <td>2167</td>\n",
       "      <td>386</td>\n",
       "      <td>5.599483</td>\n",
       "      <td>36</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>207</td>\n",
       "      <td>67.940871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00367BB2546B</td>\n",
       "      <td>Thomas Jefferson once states that \"it is wonde...</td>\n",
       "      <td>2361</td>\n",
       "      <td>442</td>\n",
       "      <td>5.329571</td>\n",
       "      <td>33</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>244</td>\n",
       "      <td>62.349525</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        text_id                                          full_text  \\\n",
       "0  0000C359D63E  when a person has no experience on a job their...   \n",
       "1  000BAD50D026  Do you think students would benefit from being...   \n",
       "2  00367BB2546B  Thomas Jefferson once states that \"it is wonde...   \n",
       "\n",
       "   char_count  word_count  word_density  punctuation_count  title_word_count  \\\n",
       "0        4224         835      5.052632                 37                25   \n",
       "1        2167         386      5.599483                 36                11   \n",
       "2        2361         442      5.329571                 33                11   \n",
       "\n",
       "   upper_case_word_count  stopword_count  flesch_kincaid_score  \n",
       "0                      1             454             67.346130  \n",
       "1                      1             207             67.940871  \n",
       "2                      1             244             62.349525  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_feat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9c85931d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T07:22:13.814466Z",
     "iopub.status.busy": "2023-08-18T07:22:13.814104Z",
     "iopub.status.idle": "2023-08-18T07:22:13.824542Z",
     "shell.execute_reply": "2023-08-18T07:22:13.823514Z"
    },
    "papermill": {
     "duration": 0.285761,
     "end_time": "2023-08-18T07:22:13.826577",
     "exception": false,
     "start_time": "2023-08-18T07:22:13.540816",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.69473333, 0.65890851, 0.02213965, 0.18137256, 0.12376237,\n",
       "        0.00271003, 0.59653793, 0.92048347],\n",
       "       [0.34971487, 0.29855538, 0.03854237, 0.17647059, 0.05445544,\n",
       "        0.00271003, 0.26764313, 0.92202658],\n",
       "       [0.38225429, 0.3434992 , 0.0304464 , 0.16176471, 0.05445544,\n",
       "        0.00271003, 0.31691077, 0.90751929]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_features():\n",
    "    eng_features_test_2 = test_feat.drop(['text_id', 'full_text'], axis = 1)\n",
    "    scaled = scaler.transform(np.array(eng_features_test_2))\n",
    "    return scaled\n",
    "get_features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0c4e8e1d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T07:22:14.386314Z",
     "iopub.status.busy": "2023-08-18T07:22:14.385956Z",
     "iopub.status.idle": "2023-08-18T07:22:14.401677Z",
     "shell.execute_reply": "2023-08-18T07:22:14.400663Z"
    },
    "papermill": {
     "duration": 0.296931,
     "end_time": "2023-08-18T07:22:14.403834",
     "exception": false,
     "start_time": "2023-08-18T07:22:14.106903",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_id</th>\n",
       "      <th>full_text</th>\n",
       "      <th>cleaned_text</th>\n",
       "      <th>text_id</th>\n",
       "      <th>char_count</th>\n",
       "      <th>word_count</th>\n",
       "      <th>word_density</th>\n",
       "      <th>punctuation_count</th>\n",
       "      <th>title_word_count</th>\n",
       "      <th>upper_case_word_count</th>\n",
       "      <th>stopword_count</th>\n",
       "      <th>flesch_kincaid_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000C359D63E</td>\n",
       "      <td>when a person has no experience on a job their...</td>\n",
       "      <td>&lt; sostok &gt; person experience job go good peopl...</td>\n",
       "      <td>0000C359D63E</td>\n",
       "      <td>4224</td>\n",
       "      <td>835</td>\n",
       "      <td>5.052632</td>\n",
       "      <td>37</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>454</td>\n",
       "      <td>67.346130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000BAD50D026</td>\n",
       "      <td>Do you think students would benefit from being...</td>\n",
       "      <td>&lt; sostok &gt; think student benefit able attend c...</td>\n",
       "      <td>000BAD50D026</td>\n",
       "      <td>2167</td>\n",
       "      <td>386</td>\n",
       "      <td>5.599483</td>\n",
       "      <td>36</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>207</td>\n",
       "      <td>67.940871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00367BB2546B</td>\n",
       "      <td>Thomas Jefferson once states that \"it is wonde...</td>\n",
       "      <td>&lt; sostok &gt; thomas jefferson state wonderful ag...</td>\n",
       "      <td>00367BB2546B</td>\n",
       "      <td>2361</td>\n",
       "      <td>442</td>\n",
       "      <td>5.329571</td>\n",
       "      <td>33</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>244</td>\n",
       "      <td>62.349525</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        text_id                                          full_text  \\\n",
       "0  0000C359D63E  when a person has no experience on a job their...   \n",
       "1  000BAD50D026  Do you think students would benefit from being...   \n",
       "2  00367BB2546B  Thomas Jefferson once states that \"it is wonde...   \n",
       "\n",
       "                                        cleaned_text       text_id  \\\n",
       "0  < sostok > person experience job go good peopl...  0000C359D63E   \n",
       "1  < sostok > think student benefit able attend c...  000BAD50D026   \n",
       "2  < sostok > thomas jefferson state wonderful ag...  00367BB2546B   \n",
       "\n",
       "   char_count  word_count  word_density  punctuation_count  title_word_count  \\\n",
       "0        4224         835      5.052632                 37                25   \n",
       "1        2167         386      5.599483                 36                11   \n",
       "2        2361         442      5.329571                 33                11   \n",
       "\n",
       "   upper_case_word_count  stopword_count  flesch_kincaid_score  \n",
       "0                      1             454             67.346130  \n",
       "1                      1             207             67.940871  \n",
       "2                      1             244             62.349525  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2b0846cc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T07:22:15.008376Z",
     "iopub.status.busy": "2023-08-18T07:22:15.008014Z",
     "iopub.status.idle": "2023-08-18T07:22:15.026599Z",
     "shell.execute_reply": "2023-08-18T07:22:15.025712Z"
    },
    "papermill": {
     "duration": 0.297523,
     "end_time": "2023-08-18T07:22:15.028905",
     "exception": false,
     "start_time": "2023-08-18T07:22:14.731382",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('/kaggle/input/feedback-prize-english-language-learning/test.csv')\n",
    "sub = pd.read_csv('/kaggle/input/feedback-prize-english-language-learning/sample_submission.csv')\n",
    "xtest_tokenizer = Tokenizer()\n",
    "xtest = test_df['cleaned_text']\n",
    "xtest_tokenizer.fit_on_texts(test_df['cleaned_text'])\n",
    "max_text_len=450\n",
    "X_test = get_training_data(test_df, xtest_tokenizer, None)\n",
    "X_feats = get_features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1ff2ece1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T07:22:15.588935Z",
     "iopub.status.busy": "2023-08-18T07:22:15.588543Z",
     "iopub.status.idle": "2023-08-18T07:22:47.699315Z",
     "shell.execute_reply": "2023-08-18T07:22:47.698321Z"
    },
    "papermill": {
     "duration": 32.656199,
     "end_time": "2023-08-18T07:22:47.965894",
     "exception": false,
     "start_time": "2023-08-18T07:22:15.309695",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 238ms/step\n"
     ]
    }
   ],
   "source": [
    "pred = model.predict([X_test, X_feats])\n",
    "\n",
    "for index, row in df_test.iterrows():\n",
    "    sub_index = sub[sub['text_id']==row['text_id']].index\n",
    "    sub.iloc[sub_index, 1] = pred[sub_index,0]\n",
    "    sub.iloc[sub_index, 2] = pred[sub_index,1]\n",
    "    sub.iloc[sub_index, 3] = pred[sub_index,2]\n",
    "    sub.iloc[sub_index, 4] = pred[sub_index,3]\n",
    "    sub.iloc[sub_index, 5] = pred[sub_index,4]\n",
    "    sub.iloc[sub_index, 6] = pred[sub_index,5]\n",
    "\n",
    "sub['text_id'] = sub['text_id']\n",
    "sub.to_csv('/kaggle/working/submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "56cc9e8f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T07:22:48.515659Z",
     "iopub.status.busy": "2023-08-18T07:22:48.515286Z",
     "iopub.status.idle": "2023-08-18T07:22:48.522893Z",
     "shell.execute_reply": "2023-08-18T07:22:48.521976Z"
    },
    "papermill": {
     "duration": 0.286324,
     "end_time": "2023-08-18T07:22:48.524924",
     "exception": false,
     "start_time": "2023-08-18T07:22:48.238600",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_sub = pd.read_csv('/kaggle/working/submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6439f400",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T07:22:49.073372Z",
     "iopub.status.busy": "2023-08-18T07:22:49.073003Z",
     "iopub.status.idle": "2023-08-18T07:22:49.085798Z",
     "shell.execute_reply": "2023-08-18T07:22:49.084861Z"
    },
    "papermill": {
     "duration": 0.289853,
     "end_time": "2023-08-18T07:22:49.087819",
     "exception": false,
     "start_time": "2023-08-18T07:22:48.797966",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_id</th>\n",
       "      <th>cohesion</th>\n",
       "      <th>syntax</th>\n",
       "      <th>vocabulary</th>\n",
       "      <th>phraseology</th>\n",
       "      <th>grammar</th>\n",
       "      <th>conventions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000C359D63E</td>\n",
       "      <td>3.079875</td>\n",
       "      <td>2.776812</td>\n",
       "      <td>2.941681</td>\n",
       "      <td>2.962804</td>\n",
       "      <td>2.738084</td>\n",
       "      <td>2.888472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000BAD50D026</td>\n",
       "      <td>2.823738</td>\n",
       "      <td>2.534441</td>\n",
       "      <td>2.793427</td>\n",
       "      <td>2.685720</td>\n",
       "      <td>2.611121</td>\n",
       "      <td>2.716066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00367BB2546B</td>\n",
       "      <td>3.089237</td>\n",
       "      <td>2.888758</td>\n",
       "      <td>3.232103</td>\n",
       "      <td>3.082988</td>\n",
       "      <td>3.164050</td>\n",
       "      <td>3.179684</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        text_id  cohesion    syntax  vocabulary  phraseology   grammar  \\\n",
       "0  0000C359D63E  3.079875  2.776812    2.941681     2.962804  2.738084   \n",
       "1  000BAD50D026  2.823738  2.534441    2.793427     2.685720  2.611121   \n",
       "2  00367BB2546B  3.089237  2.888758    3.232103     3.082988  3.164050   \n",
       "\n",
       "   conventions  \n",
       "0     2.888472  \n",
       "1     2.716066  \n",
       "2     3.179684  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sub.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 641.856979,
   "end_time": "2023-08-18T07:22:52.330038",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-08-18T07:12:10.473059",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
